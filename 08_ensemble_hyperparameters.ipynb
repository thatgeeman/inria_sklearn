{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444ae319",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "In the previous section, we did not discuss the parameters of random forest\n",
    "and gradient-boosting. However, there are a couple of things to keep in mind\n",
    "when setting these.\n",
    "\n",
    "This notebook gives crucial information regarding how to set the\n",
    "hyperparameters of both random forest and gradient boosting decision tree\n",
    "models.\n",
    "\n",
    "<div class=\"admonition caution alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p class=\"last\">For the sake of clarity, no cross-validation will be used to estimate the\n",
    "testing error. We are only showing the effect of the parameters\n",
    "on the validation set of what should be the inner cross-validation.</p>\n",
    "</div>\n",
    "\n",
    "## Random forest\n",
    "\n",
    "The main parameter to tune for random forest is the `n_estimators` parameter.\n",
    "In general, the more trees in the forest, the better the statistical\n",
    "performance will be. However, it will slow down the fitting and prediction\n",
    "time. The goal is to balance computing time and statistical performance when\n",
    "setting the number of estimators when putting such learner in production.\n",
    "\n",
    "The `max_depth` parameter could also be tuned. Sometimes, there is no need\n",
    "to have fully grown trees. However, be aware that with random forest, trees\n",
    "are generally deep since we are seeking to overfit the learners on the\n",
    "bootstrap samples because this will be mitigated by combining them.\n",
    "Assembling underfitted trees (i.e. shallow trees) might also lead to an\n",
    "underfitted forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7af3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd5b73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>34.447077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>34.960181</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>35.972989</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>48.565764</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>48.590271</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>48.620697</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>57.150659</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>57.245916</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>57.329018</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_depth  mean_test_score  rank_test_score\n",
       "8                 30            None        34.447077                1\n",
       "7                 20            None        34.960181                2\n",
       "6                 10            None        35.972989                3\n",
       "3                 10               5        48.565764                4\n",
       "4                 20               5        48.590271                5\n",
       "5                 30               5        48.620697                6\n",
       "2                 30               3        57.150659                7\n",
       "0                 10               3        57.245916                8\n",
       "1                 20               3        57.329018                9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 20, 30],\n",
    "    \"max_depth\": [3, 5, None],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(n_jobs=-1), param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=-1,\n",
    ")\n",
    "grid_search.fit(data_train, target_train)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c256ce",
   "metadata": {},
   "source": [
    "if max_depth is none, the maximum depth until good seperatiion occurs is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fca0c7",
   "metadata": {},
   "source": [
    "We can observe that in our grid-search, the largest `max_depth` together\n",
    "with the largest `n_estimators` led to the best statistical performance.\n",
    "\n",
    "## Gradient-boosting decision trees\n",
    "\n",
    "For gradient-boosting, parameters are coupled, so we cannot set the\n",
    "parameters one after the other anymore. The important parameters are\n",
    "`n_estimators`, `max_depth`, and `learning_rate`.\n",
    "\n",
    "Let's first discuss the `max_depth` parameter.\n",
    "We saw in the section on gradient-boosting that the algorithm fits the error\n",
    "of the previous tree in the ensemble. Thus, fitting fully grown trees will\n",
    "be detrimental.\n",
    "Indeed, the first tree of the ensemble would perfectly fit (overfit) the data\n",
    "and thus no subsequent tree would be required, since there would be no\n",
    "residuals.\n",
    "Therefore, the tree used in gradient-boosting should have a low depth,\n",
    "typically between 3 to 8 levels. Having very weak learners at each step will\n",
    "help reducing overfitting.\n",
    "\n",
    "With this consideration in mind, the deeper the trees, the faster the\n",
    "residuals will be corrected and less learners are required. Therefore,\n",
    "`n_estimators` should be increased if `max_depth` is lower.\n",
    "\n",
    "Finally, we have overlooked the impact of the `learning_rate` parameter\n",
    "until now. When fitting the residuals, we would like the tree\n",
    "to try to correct all possible errors or only a fraction of them.\n",
    "The learning-rate allows you to control this behaviour.\n",
    "A small learning-rate value would only correct the residuals of very few\n",
    "samples. If a large learning-rate is set (e.g., 1), we would fit the\n",
    "residuals of all samples. So, with a very low learning-rate, we will need\n",
    "more estimators to correct the overall error. However, a too large\n",
    "learning-rate tends to obtain an overfitted ensemble,\n",
    "similar to having a too large tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33d32169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_iter_no_change</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>31.900878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>33.628074</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>35.188711</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>35.666047</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>35.795670</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>36.015955</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>36.715120</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>37.101835</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>37.438212</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>38.399189</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>38.892854</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>38.986004</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>39.117992</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39.138803</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>39.175252</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39.298585</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>39.363569</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>39.449998</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39.471530</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>39.879999</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39.905621</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>40.501427</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>40.602042</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>41.495408</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>41.589715</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>43.874540</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>45.590744</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>45.603858</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>45.756084</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>45.865738</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>45.965479</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>46.574499</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.259152</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>47.316082</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>47.461794</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>47.508840</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>47.529984</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.589267</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.706858</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.793343</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.979261</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>48.522343</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>51.981403</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>52.726878</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>56.358043</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>56.394294</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>62.172636</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>62.270268</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_estimators param_max_depth param_learning_rate  \\\n",
       "15                200               5                 0.1   \n",
       "14                200               5                 0.1   \n",
       "7                 200               3                 0.1   \n",
       "13                 50               5                 0.1   \n",
       "12                 50               5                 0.1   \n",
       "6                 200               3                 0.1   \n",
       "29                 50               3                   1   \n",
       "31                200               3                   1   \n",
       "27                 30               3                   1   \n",
       "30                200               3                   1   \n",
       "28                 50               3                   1   \n",
       "26                 30               3                   1   \n",
       "35                 30               5                   1   \n",
       "38                200               5                   1   \n",
       "10                 30               5                 0.1   \n",
       "36                 50               5                   1   \n",
       "11                 30               5                 0.1   \n",
       "33                 10               5                   1   \n",
       "34                 30               5                   1   \n",
       "37                 50               5                   1   \n",
       "32                 10               5                   1   \n",
       "4                  50               3                 0.1   \n",
       "5                  50               3                 0.1   \n",
       "24                 10               3                   1   \n",
       "25                 10               3                   1   \n",
       "39                200               5                   1   \n",
       "2                  30               3                 0.1   \n",
       "19                 30            None                 0.1   \n",
       "3                  30               3                 0.1   \n",
       "21                 50            None                 0.1   \n",
       "23                200            None                 0.1   \n",
       "18                 30            None                 0.1   \n",
       "20                 50            None                 0.1   \n",
       "43                 30            None                   1   \n",
       "41                 10            None                   1   \n",
       "47                200            None                   1   \n",
       "45                 50            None                   1   \n",
       "22                200            None                 0.1   \n",
       "46                200            None                   1   \n",
       "40                 10            None                   1   \n",
       "44                 50            None                   1   \n",
       "42                 30            None                   1   \n",
       "17                 10            None                 0.1   \n",
       "16                 10            None                 0.1   \n",
       "9                  10               5                 0.1   \n",
       "8                  10               5                 0.1   \n",
       "0                  10               3                 0.1   \n",
       "1                  10               3                 0.1   \n",
       "\n",
       "   param_n_iter_no_change  mean_test_score  rank_test_score  \n",
       "15                   None        31.900878                1  \n",
       "14                      3        33.628074                2  \n",
       "7                    None        35.188711                3  \n",
       "13                   None        35.666047                4  \n",
       "12                      3        35.795670                5  \n",
       "6                       3        36.015955                6  \n",
       "29                   None        36.715120                7  \n",
       "31                   None        37.101835                8  \n",
       "27                   None        37.438212                9  \n",
       "30                      3        38.399189               10  \n",
       "28                      3        38.892854               11  \n",
       "26                      3        38.986004               12  \n",
       "35                   None        39.117992               13  \n",
       "38                      3        39.138803               14  \n",
       "10                      3        39.175252               15  \n",
       "36                      3        39.298585               16  \n",
       "11                   None        39.363569               17  \n",
       "33                   None        39.449998               18  \n",
       "34                      3        39.471530               19  \n",
       "37                   None        39.879999               20  \n",
       "32                      3        39.905621               21  \n",
       "4                       3        40.501427               22  \n",
       "5                    None        40.602042               23  \n",
       "24                      3        41.495408               24  \n",
       "25                   None        41.589715               25  \n",
       "39                   None        43.874540               26  \n",
       "2                       3        45.590744               27  \n",
       "19                   None        45.603858               28  \n",
       "3                    None        45.756084               29  \n",
       "21                   None        45.865738               30  \n",
       "23                   None        45.965479               31  \n",
       "18                      3        46.574499               32  \n",
       "20                      3        47.259152               33  \n",
       "43                   None        47.316082               34  \n",
       "41                   None        47.461794               35  \n",
       "47                   None        47.508840               36  \n",
       "45                   None        47.529984               37  \n",
       "22                      3        47.589267               38  \n",
       "46                      3        47.706858               39  \n",
       "40                      3        47.793343               40  \n",
       "44                      3        47.979261               41  \n",
       "42                      3        48.522343               42  \n",
       "17                   None        51.981403               43  \n",
       "16                      3        52.726878               44  \n",
       "9                    None        56.358043               45  \n",
       "8                       3        56.394294               46  \n",
       "0                       3        62.172636               47  \n",
       "1                    None        62.270268               48  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 30, 50,200],\n",
    "    \"max_depth\": [3, 5, None],\n",
    "    \"learning_rate\": [0.1, 1],\n",
    "    \"n_iter_no_change\": [3, None] # early stopping if no change for 3 iters\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    GradientBoostingRegressor(), param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=-1\n",
    ")\n",
    "grid_search.fit(data_train, target_train)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70611de2",
   "metadata": {},
   "source": [
    "<div class=\"admonition caution alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Caution!</p>\n",
    "<p class=\"last\">Here, we tune the <tt class=\"docutils literal\">n_estimators</tt> but be aware that using early-stopping as\n",
    "in the previous exercise will be better.</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "nbreset": "https://github.com/INRIA/scikit-learn-mooc/raw/master/notebooks/ensemble_hyperparameters.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
